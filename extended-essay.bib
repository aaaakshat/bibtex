Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@misc{W.Patchin2019,
author = {{W. Patchin}, Justin},
booktitle = {Cyberbullying Research Center},
month = {jul},
title = {{Summary of Our Cyberbullying Research (2004-2016)}},
url = {https://cyberbullying.org/summary-of-our-cyberbullying-research},
urldate = {2020-06-07},
year = {2019}
}
@article{Vanian2019,
author = {Vanian, Jonathan},
journal = {Fortune},
month = {may},
title = {{Keep Your A.I. Buzzwords Straight}},
url = {https://fortune.com/2019/05/28/ai-buzzwords/},
year = {2019}
}
@article{Biswas,
abstract = {Sentiment analysis is a well researched natural language processing field. It is a challenging machine learning task due to the recursive nature of sentences, different length of documents and sarcasm. Traditional approaches to sentiment analysis use count or frequency of words in the text which are assigned sentiment value by some expert. These approaches disregard the order of words and the complex meanings they can convey. Gated Recurrent Units are recent form of recurrent neural network which have the ability to store information of long term dependencies in sequential data. In this work we showed that GRU are suitable for processing long textual data and applied it to the task of sentiment analysis. We showed its effectiveness by comparing with tf-idf and word2vec models. We also showed that GRUs are faster in convergence than LSTM, another gating network. We applied a number of modifications to the standard GRU to make it train faster and yet less prone to over training. We found the better performimg hyperparameters of the GRU-net through extensive cross-validation testing. Finally we ensembled the best performing GRU models for even better performance.},
author = {Biswas, Shamim and Chadda, Ekamber and Ahmad, Faiyaz},
file = {::},
issn = {2393-9915},
journal = {Advances in Computer Science and Information Technology (ACSIT)},
keywords = {Sentiment analysis,ensemble,gated recurrent unit,kaggle},
month = {apr},
number = {11},
pages = {59--63},
title = {{Sentiment Analysis with Gated Recurrent Units}},
url = {http://www.krishisanskriti.org/acsit.html},
volume = {2}
}
@misc{Clement2020,
author = {Clement, J.},
booktitle = {Statista},
month = {jun},
title = {{Global digital population as of April 2020}},
url = {https://www.statista.com/statistics/617136/digital-population-worldwide/},
urldate = {2020-06-07},
year = {2020}
}
@techreport{McCarthy1955,
author = {McCarthy, J. and Minsky, M. and Rochester, N. and Shannon, C.E.},
file = {::},
institution = {Dartmouth College},
month = {aug},
title = {{A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence}},
year = {1955}
}
@misc{JeanneDugan1996,
author = {{Jeanne Dugan}, I.},
booktitle = {Bloomberg},
month = {oct},
title = {{`The Internet Is The Great Equalizer'}},
url = {https://www.bloomberg.com/news/articles/1996-10-20/the-internet-is-the-great-equalizer},
urldate = {2020-06-07},
year = {1996}
}
@techreport{Yin2017,
abstract = {Deep neural networks (DNNs) have revolutionized the field of natural language processing (NLP). Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN), the two main types of DNN architectures, are widely explored to handle various NLP tasks. CNN is supposed to be good at extracting position-invariant features and RNN at modeling units in sequence. The state-of-the-art on many NLP tasks often switches due to the battle of CNNs and RNNs. This work is the first systematic comparison of CNN and RNN on a wide range of representative NLP tasks, aiming to give basic guidance for DNN selection.},
archivePrefix = {arXiv},
arxivId = {1702.01923v1},
author = {Yin, Wenpeng and Kann, Katharina and Yu, Mo and Sch{\"{u}}tzeSch, Hinrich and Munich, Lmu},
eprint = {1702.01923v1},
file = {::},
pages = {7},
title = {{Comparative Study of CNN and RNN for Natural Language Processing}},
year = {2017}
}
@article{Ahmad2017,
abstract = {Energy prediction models are used in buildings as a performance evaluation engine in advanced control and optimisation, and in making informed decisions by facility managers and utilities for enhanced energy efficiency. Simplified and data-driven models are often the preferred option where pertinent information for detailed simulation are not available and where fast responses are required. We compared the performance of the widely-used feed-forward back-propagation artificial neural network (ANN) with random forest (RF), an ensemble-based method gaining popularity in prediction â€“ for predicting the hourly HVAC energy consumption of a hotel in Madrid, Spain. Incorporating social parameters such as the numbers of guests marginally increased prediction accuracy in both cases. Overall, ANN performed marginally better than RF with root-mean-square error (RMSE) of 4.97 and 6.10 respectively. However, the ease of tuning and modelling with categorical variables offers ensemble-based algorithms an advantage for dealing with multi-dimensional complex data, typical in buildings. RF performs internal cross-validation (i.e. using out-of-bag samples) and only has a few tuning parameters. Both models have comparable predictive power and nearly equally applicable in building energy applications.},
author = {Ahmad, Muhammad Waseem and Mourshed, Monjur and Rezgui, Yacine},
doi = {10.1016/j.enbuild.2017.04.038},
file = {::},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Artificial neural networks,Data mining,Decision trees,Energy efficiency,Ensemble algorithms,HVAC systems,Random forest},
month = {jul},
pages = {77--89},
publisher = {Elsevier Ltd},
title = {{Trees vs Neurons: Comparison between random forest and ANN for high-resolution prediction of building energy consumption}},
volume = {147},
year = {2017}
}
@misc{Hern2019,
author = {Hern, Alex},
booktitle = {The Guardian},
month = {sep},
title = {{Revealed: catastrophic effects of working as a Facebook moderator | Technology | The Guardian}},
url = {https://www.theguardian.com/technology/2019/sep/17/revealed-catastrophic-effects-working-facebook-moderator},
urldate = {2020-06-07},
year = {2019}
}
